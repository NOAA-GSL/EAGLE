#!/usr/bin/env bash

set -eu

# Set tool and package versions.

flash_attn=2.8.3
python=3.12
torch=2.8
uv=0.9.13
uwtools=2.12.0

packages=(
  anemoi-datasets==0.5.*
  anemoi-graphs==0.6.*
  anemoi-inference==0.6.*
  anemoi-models==0.8.*
  anemoi-training==0.5.*
  torch==$torch.*
  ufs2arco==0.17.*
)

# Define runtime location.

runtime=$PWD/runtime

# Install uv.

curl -LsSf https://astral.sh/uv/$uv/install.sh | env UV_UNMANAGED_INSTALL=$runtime/bin sh

# Install Python.

$runtime/bin/uv python install $python --install-dir $runtime/opt --no-bin --no-cache

# Create empty virtual environment.

$(find $runtime/opt -type f -name python$python) -m venv $runtime/env

# Create extra-setup shell fragment and arrange for activation to execute it.

cudamod=$(module --terse spider cuda | grep -v "^$" | tail -n1)
test -z "${cudamod:-}" && echo "Found no CUDA module to load" && exit 1
activate=$runtime/env/bin/activate
extra=$activate.extra
cat <<EOF >$extra
module load $cudamod
export XDG_CACHE_HOME=\$(readlink -f \$(dirname \${BASH_SOURCE[0]})/../../)/var/cache
EOF
extracmd="source $(basename $extra)"
grep -q "$extracmd" $activate || echo $extracmd >>$activate

# Activate the virtual environment.

source $activate

# Install or upgrade core packages in the virtual environment.

python -m pip install pip --upgrade
python -m pip install ${packages[*]}

# Install uwtools (via git) in virtual environment.

python -m pip install "git+https://github.com/ufs-community/uwtools@v$uwtools#subdirectory=src"

# Install flash-attention in the virtual environment.

cu=$(nvcc --version | grep release | sed -E 's/^.*release ([0-9]+).*/\1/')
py=$(python --version | sed -E 's/Python ([0-9]+)\.([0-9]+)\..*/\1\2/')
fn=flash_attn-${flash_attn}+cu${cu}torch${torch}cxx11abiTRUE-cp${py}-cp${py}-linux_$(uname -p).whl
url=https://github.com/Dao-AILab/flash-attention/releases/download/v${flash_attn}/$fn
python -m pip install $url
